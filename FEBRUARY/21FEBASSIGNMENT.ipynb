{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 21 FEBRUARY ASSIGNMENT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The technique of obtaining data from websites using automated tools or software is known as web scraping. It entails using a programme to gather and process data from web sites, which is then examined, altered, and used for a variety of reasons.\n",
    "\n",
    "Web scraping is often used to obtain data in three areas:\n",
    "\n",
    "* Web scraping is often used in e-commerce to obtain data about competitor websites' products, prices, and promotions. This information can be used to modify price strategies, generate new goods, or discover market gaps.\n",
    "\n",
    "* Web scraping is used in research and analytics to collect data on a variety of areas such as social media sentiment, online reviews, and news items. This information can be utilised to spot patterns, examine consumer behaviour, and make data-driven decisions.\n",
    "\n",
    "* Web scraping is used in finance to collect information such as stock prices, financial accounts, and news items. This information can be used to forecast market trends, create trading strategies, and make investment decisions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. What are the different methods used for Web Scraping?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Web scraping can be done in a variety of ways, including:\n",
    "\n",
    "* Manual web scraping is the manual extraction of data from a website by copying and pasting it into a spreadsheet or database. While this method is time-consuming and labor-intensive, it may be appropriate for scraping tiny amounts of data or when the website is inaccessible using automated methods.\n",
    "\n",
    "* Online Scraping Tools: There are numerous web scraping tools available that allow users to automatically retrieve data from websites. These tools normally operate by sending queries to the server of the website, parsing the HTML code, and extracting the needed data. BeautifulSoup, Scrapy, and Selenium are some prominent web scraping solutions.\n",
    "* DOM Parsing: The Document Object Model (DOM) defines the structure, style and content of an XML file. Scrapers typically use a DOM parser to view the structure of web pages in depth. DOM parsers can be used to access the nodes that contain information and scrape the web page with tools like XPath."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. What is Beautiful Soup? Why is it used?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beautiful Soup is a Python package that is used for web scraping. It includes a series of tools for parsing and extracting data from HTML and XML texts. Lovely Soup makes it simple to navigate and search through a web page's HTML code in order to extract the needed info.\n",
    "\n",
    "Beautiful Soup is used for web scraping for the following reasons:\n",
    "\n",
    "* Simple to Use: Beautiful Soup is a user-friendly interface for parsing and extracting data from HTML and XML texts. Its syntax is basic and intuitive, allowing it to be used by anyone with little programming experience.\n",
    "\n",
    "* Beautiful Soup's powerful parsing capabilities allow it to parse even poorly structured HTML, making it a versatile tool for web scraping. It can extract data from nested tags and handle sophisticated HTML structures.\n",
    "\n",
    "* Integration with Other Tools: To automate web scraping operations and alter data, Beautiful Soup may be simply combined with other Python packages such as Requests and Pandas.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. Why is flask used in this Web Scraping project?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flask is a lightweight and versatile Python web framework that is often used for building online apps and APIs. Flask is frequently used in web scraping projects because it provides a quick and easy approach to create a web application that displays the scraped data.\n",
    "\n",
    "The following are some of the reasons why Flask is utilised in web scraping projects:\n",
    "\n",
    "* Flask is simple to install and configure, making it an appealing option for web scraping projects.\n",
    "\n",
    "* Flask is a lightweight framework, which means it takes up little space and can run on low-powered devices. This makes it an efficient alternative for small-scale data scraping.\n",
    "* Flask is a versatile framework that can be quickly adapted to meet the needs of specific projects. It may be used to create simple web apps that show scraped data as well as more advanced apps that involve user authentication and data manipulation.\n",
    "\n",
    "* Flask may easily be linked with other Python tools, such as Beautiful Soup and Pandas, to automate the web scraping process and alter data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. Write the names of AWS services used in this project. Also, explain the use of each service."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code Pipeling and Bean Stack are the services used in the project\n",
    "\n",
    "* AWS CodePipeline is a continuous delivery service that automates the release process for software applications. It allows you to create a pipeline of stages that automatically build, test, and deploy your code whenever changes are made to the source code repository.\n",
    "\n",
    "* AWS Elastic Beanstalk is a fully managed service for deploying and scaling web applications and services written in Java,.NET, PHP, Node.js, Python, Ruby, Go, and Docker. Elastic Beanstalk automates your application's deployment, capacity provisioning, load balancing, and auto-scaling for you, allowing you to focus on developing code rather than managing infrastructure."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
