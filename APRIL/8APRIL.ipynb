{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 APRIL ASSIGNMENT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. In order to predict house price based on several characteristics, such as location, square footage,\n",
    "number of bedrooms, etc., you are developing an SVM regression model. Which regression metric in this\n",
    "situation would be the best to employ?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some of the metrics that are commonly used:\n",
    "\n",
    "1. Mean Squared Error (MSE): MSE is a commonly used regression measure that computes the average squared difference between predicted and actual values. It penalises greater mistakes more than smaller ones. MSE minimization entails lowering the total average error.\n",
    "\n",
    "2. Root Mean Squared Error (RMSE): Like MSE, RMSE calculates the square root of the average squared difference between anticipated and actual values. When you want the error measure to be in the same units as the target variable (for example, dollars in the case of housing prices), RMSE is beneficial.\n",
    "3. Mean Absolute Error (MAE): The average absolute difference between anticipated and actual values is calculated using MAE. It calculates the average size of mistakes without taking into account their direction. When compared to MSE, MAE is less susceptible to outliers.\n",
    "\n",
    "4. R-squared (R2) or Coefficient of Determination: R-squared calculates the proportion of the variation in the target variable that can be explained by the model's independent variables. It has a scale of 0 to 1, with 1 indicating a perfect fit. R-squared may be used to determine how effectively the model captures variation in the target variable.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. You have built an SVM regression model and are trying to decide between using MSE or R-squared as\n",
    "your evaluation metric. Which metric would be more appropriate if your goal is to predict the actual price\n",
    "of a house as accurately as possible?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to be as exact as possible in predicting the real price of a property, the Mean Squared Error (MSE) would be a better assessment metric for your SVM regression model.\n",
    "\n",
    "The average squared difference between expected and actual values is measured by MSE. MSE lends greater weight to larger errors by squaring them, making it a good choice when you want to focus on minimising the total size of errors. Minimising the MSE in the context of house price prediction, where the aim is to estimate the real price with high accuracy, results in a model that delivers forecasts that are closer to the genuine values on average.\n",
    "\n",
    "R-squared (Coefficient of Determination) reflects the proportion of the variation in the target variable that can be explained by the model's independent variables. While R-squared is a useful indicator for determining how well a model fits the data and explains variation, it may not directly represent individual prediction accuracy. R-squared is more concerned with the amount of variation explained rather than the magnitude of mistakes, therefore it may not be as clearly linked with the objective of accurate home price prediction.\n",
    "\n",
    "As a result, if your primary aim is to properly estimate the real price of a property, MSE would be a better assessment metric to analyse the success of your SVM regression model.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. You have a dataset with a significant number of outliers and are trying to select an appropriate\n",
    "regression metric to use with your SVM model. Which metric would be the most appropriate in this\n",
    "scenario?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have a dataset with a substantial number of outliers and are using an SVM regression model, the Mean Absolute Error (MAE) is the best regression statistic to utilise in this situation.\n",
    "\n",
    "MAE calculates the average absolute difference between expected and actual values without taking into account their direction. Because it does not square the errors, it is less susceptible to outliers than the Mean Squared Error (MSE). This characteristic makes MAE more resilient and less sensitive to outliers in the dataset.\n",
    "\n",
    "When there are a large number of outliers, the squared errors in MSE might be disproportionately impacted, resulting in an inflated error measure. MAE, on the other hand, provides equal weight to all mistakes, regardless of size. This indicates that the existence of outliers has less of an influence on the total error computation.\n",
    "\n",
    "By employing MAE as your SVM regression model's evaluation measure, you may obtain a more accurate depiction of the average magnitude of errors in your predictions, even in the presence of outliers. This might assist you in evaluating the performance of your model and making more dependable forecasts.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. You have built an SVM regression model using a polynomial kernel and are trying to select the best\n",
    "metric to evaluate its performance. You have calculated both MSE and RMSE and found that both values\n",
    "are very close. Which metric should you choose to use in this case?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you've developed an SVM regression model with a polynomial kernel and calculated both Mean Squared Error (MSE) and Root Mean Squared Error (RMSE) and discovered that both values are fairly close, you may use either measure to evaluate the performance of your model. In this scenario, however, RMSE is frequently recommended over MSE as the assessment statistic for the following reasons:\n",
    "\n",
    "1. Interpretability: Because it is in the same units as the target variable, RMSE is more interpretable than MSE. This makes it easy to comprehend the size of the mistakes and immediately compare them to the scale of the original target variable. For example, if you are estimating property values in dollars, RMSE will give you an error number in dollars, which is more convenient.\n",
    "\n",
    "2. Sensitivity to outliers: When compared to MSE, RMSE is more sensitive to outliers. RMSE accentuates the impact of greater mistakes because it entails computing the square root of the mean squared errors. This makes RMSE a good choice if you wish to penalise greater mistakes more severely, especially if outliers are a major problem in your regression work.\n",
    "\n",
    "\n",
    "3. RMSE is a popular assessment measure in regression tasks, and it is frequently cited in research articles and industrial applications. Using RMSE ensures conformity with industry standards and allows for easy comparison with other models or benchmark results.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. You are comparing the performance of different SVM regression models using different kernels (linear,\n",
    "polynomial, and RBF) and are trying to select the best evaluation metric. Which metric would be most\n",
    "appropriate if your goal is to measure how well the model explains the variance in the target variable?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to compare how well different SVM regression models with different kernels (linear, polynomial, and RBF) explain the variance in the target variable, the coefficient of determination, also known as R-squared (R2), is the best evaluation metric.\n",
    "\n",
    "R-squared calculates the proportion of the variation in the target variable that can be explained by the model's independent variables. It has a value between 0 and 1, with 0 indicating that the model explains none of the variation and 1 indicating that the model explains all of the variance. In the context of regression models, a higher R-squared value implies a better fit of the model to the data and shows that the model's predictions account for a greater share of the variation in the target variable.\n",
    "\n",
    "You may immediately test and compare how well each SVM regression model with different kernels explains the variation in the target variable by using R-squared as the evaluation metric. This will help you to identify which kernel captures the underlying patterns and trends in the data the best, resulting in a higher degree of explained variance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
